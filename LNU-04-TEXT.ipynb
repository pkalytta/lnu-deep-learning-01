{"cells":[{"cell_type":"markdown","metadata":{"id":"t09eeeR5prIJ"},"source":["##### Copyright 2019 The TensorFlow Authors. | 2021 Philipp Kalytta"]},{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","id":"GCCk8_dHpuNf","executionInfo":{"status":"ok","timestamp":1650699081079,"user_tz":-120,"elapsed":329,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"ovpZyIhNIgoq"},"source":["# Text Generierung mit einem Recurrent Neural Network\n"]},{"cell_type":"markdown","metadata":{"id":"hcD2nPQvPOFM"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/text/text_generation\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/text_generation.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"BwpJ5IffzRG6"},"source":["Hier wird demonstriert, wie man mit einem zeichenbasierten RNN Text erzeugt. DU kannst hier mit einem Datensatz von Shakespeares Schriften aus dem Buch [The Unreasonable Effectiveness of Recurrent Neural Networks] von Andrej Karpathy (http://karpathy.github.io/2015/05/21/rnn-effectiveness/) arbeiten, oder deine eigene Textdatei verwenden. Geben Sie eine Sequenz von Zeichen aus diesen Daten (\"Shakespeare\") und trainieren Sie ein Modell, um das nächste Zeichen in der Sequenz (\"e\") vorherzusagen. Längere Textsequenzen können durch wiederholtes Aufrufen des Modells erzeugt werden.\n","\n","Hinweis: Aktivieren Sie die GPU-Beschleunigung, um dieses Notizbuch schneller auszuführen. In Colab: *Laufzeit > Laufzeittyp ändern > Hardwarebeschleuniger > GPU*.\n","\n","Dieses Colab-Book enthält lauffähigen Code, der mit [tf.keras] (https://www.tensorflow.org/guide/keras/sequential_model) und [eager execution] (https://www.tensorflow.org/guide/eager) implementiert wurde. Im Folgenden siehst du die Beispielausgabe, wenn das Modell in diesem Programm 30 Epochen lang trainiert und mit dem Zeichen \"Q\" gestartet wurde:"]},{"cell_type":"markdown","metadata":{"id":"HcygKkEVZBaa"},"source":["<pre>\n","QUEENE:\n","I had thought thou hadst a Roman; for the oracle,\n","Thus by All bids the man against the word,\n","Which are so weak of care, by old care done;\n","Your children were in your holy love,\n","And the precipitation through the bleeding throne.\n","\n","BISHOP OF ELY:\n","Marry, and will, my lord, to weep in such a one were prettiest;\n","Yet now I was adopted heir\n","Of the world's lamentable day,\n","To watch the next way with his father with his face?\n","\n","ESCALUS:\n","The cause why then we are all resolved more sons.\n","\n","VOLUMNIA:\n","O, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, it is no sin it should be dead,\n","And love and pale as any will to that word.\n","\n","QUEEN ELIZABETH:\n","But how long have I heard the soul for this world,\n","And show his hands of life be proved to stand.\n","\n","PETRUCHIO:\n","I say he look'd on, if I must be content\n","To stay him from the fatal of our country's bliss.\n","His lordship pluck'd from this sentence then for prey,\n","And then let us twain, being the moon,\n","were she such a case as fills m\n","</pre>"]},{"cell_type":"markdown","metadata":{"id":"_bGsCP9DZFQ5"},"source":["Während einige der Sätze grammatikalisch korrekt sind, ergeben die meisten keinen Sinn. Das Modell hat nicht die Bedeutung der Wörter gelernt:\n","\n","* Das Modell ist zeichenbasiert. Als das Training begann, wusste das Modell nicht, wie ein englisches Wort geschrieben wird oder dass Wörter überhaupt eine Texteinheit sind.\n","\n","* Die Struktur der Ausgabe ähnelt einem Theaterstück - die Textblöcke beginnen in der Regel mit dem Namen des Sprechers, in Großbuchstaben, ähnlich wie im Datensatz.\n","\n","* Wie unten gezeigt wird, wird das Modell auf kleinen Textmengen (je 100 Zeichen) trainiert und ist dennoch in der Lage, eine längere Textfolge mit kohärenter Struktur zu erzeugen."]},{"cell_type":"markdown","metadata":{"id":"srXC6pLGLwS6"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"WGyKZj3bzf9p"},"source":["### Import TensorFlow and other libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"yG_n40gFzf9s","executionInfo":{"status":"ok","timestamp":1650699084317,"user_tz":-120,"elapsed":3027,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers.experimental import preprocessing\n","\n","import numpy as np\n","import os\n","import time"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"De9rX7Nop2Ac","executionInfo":{"status":"ok","timestamp":1650699084317,"user_tz":-120,"elapsed":16,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context"]},{"cell_type":"markdown","metadata":{"id":"EHDoRoc5PKWz"},"source":["### Download the Shakespeare dataset\n","\n","Ändere die folgende Zeile, wenn du deinen eigenen Datensatz verwenden willst. Dafür muss der Datensatz als Textdatei im Internet verfügbar sein.\n","\n","Hier gibt es z.B. die Bibel: \n","https://info1.sermon-online.com/german/MartinLuther-1912/Martin_Luther_Uebersetzung_1912.txt\n","https://www.sermon-online.de/search.pl?lang=de&id=6068\n","\n","Oder hier Goethes Faust:\n","https://raw.githubusercontent.com/martinth/mobverdb/master/faust.txt\n","\n","Star Wars Screenplay: http://www.scifiscripts.com/scripts/swd1_5-74.txt\n","\n","Der Datensatz sollte möglichst groß sein, aber nicht zu groß."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":398,"status":"ok","timestamp":1650699084699,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"pD_55cOxLkAb","outputId":"f44c6392-e6c2-4f7d-977c-b99e1f69ac9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://raw.githubusercontent.com/martinth/mobverdb/master/faust.txt\n","573440/568500 [==============================] - 0s 0us/step\n","581632/568500 [==============================] - 0s 0us/step\n"]}],"source":["#path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n","#path_to_file = tf.keras.utils.get_file(\"bibel.txt\", \"https://info1.sermon-online.com/german/MartinLuther-1912/Martin_Luther_Uebersetzung_1912.txt\")\n","path_to_file = tf.keras.utils.get_file(\"goethe.txt\", \"https://raw.githubusercontent.com/martinth/mobverdb/master/faust.txt\")\n"]},{"cell_type":"markdown","metadata":{"id":"UHjdCjDuSvX_"},"source":["### Read the data\n","\n","Schauen wir uns den Text mal an. - Sollte das Format nicht utf-8 sein, muss hier natürlich ein anderes Format gewählt werden. z.B. cp1252 für Windows"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1650699084700,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"aavnuByVymwK","outputId":"15cf5853-b72c-4d42-985d-867a477351a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Length of text: 560933 characters\n"]}],"source":["# Read, then decode for py2 compat.\n","#text = open(path_to_file, 'rb').read().decode(encoding='cp1252')\n","text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n","# length of text is the number of characters in it\n","print(f'Length of text: {len(text)} characters')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1650699084700,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"Duhg9NrUymwO","outputId":"1b15f5a5-620c-4af6-a7c8-9f5027257c5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["The Project Gutenberg EBook of Faust: Der Tragödie erster Teil, by \r\n","Johann Wolfgang von Goethe\r\n","\r\n","This eBook is for the use of anyone anywhere at no cost and with\r\n","almost no restrictions whatsoever.  You may copy it, give it away or\r\n","re-use it under\n"]}],"source":["# Take a look at the first 250 characters in text\n","print(text[:250])"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2485,"status":"ok","timestamp":1650699087178,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"IlCgQBRVymwR","outputId":"b09e3388-3827-473d-af79-8f77c06b71d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["94 unique characters\n"]}],"source":["# The unique characters in the file\n","vocab = sorted(set(text))\n","print(f'{len(vocab)} unique characters')"]},{"cell_type":"markdown","metadata":{"id":"rNnrKn_lL-IJ"},"source":["## Process the text"]},{"cell_type":"markdown","metadata":{"id":"LFjSVAlWzf-N"},"source":["### Vektorisierung des Textes\n","\n","Vor dem Training müssen Sie die Strings in eine numerische Darstellung umwandeln. \n","\n","Die Schicht `preprocessing.StringLookup` kann jedes Zeichen in eine numerische ID umwandeln. Dazu muss der Text zunächst in Token zerlegt werden."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1650699087415,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"a86OoYtO01go","outputId":"af1003d0-6f51-4696-a827-4d36a35d20cf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"]},"metadata":{},"execution_count":8}],"source":["example_texts = ['abcdefg', 'xyz']\n","\n","chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n","chars"]},{"cell_type":"markdown","metadata":{"id":"1s4f1q3iqY8f"},"source":["*Nun* erstellen Sie die Schicht \"Preprocessing.StringLookup\":"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"6GMlCe3qzaL9","executionInfo":{"status":"ok","timestamp":1650699087653,"user_tz":-120,"elapsed":242,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["ids_from_chars = preprocessing.StringLookup(\n","    vocabulary=list(vocab))"]},{"cell_type":"markdown","metadata":{"id":"ZmX_jbgQqfOi"},"source":["*Es* konvertiert Form-Token in Zeichen-IDs, die mit `0` aufgefüllt werden:"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1650699087653,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"WLv5Q_2TC2pc","outputId":"0a8db84d-426e-47a7-ba61-07d366ea19c3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.RaggedTensor [[61, 62, 63, 64, 65, 66, 67], [84, 85, 86]]>"]},"metadata":{},"execution_count":10}],"source":["ids = ids_from_chars(chars)\n","ids"]},{"cell_type":"markdown","metadata":{"id":"tZfqhkYCymwX"},"source":["Da das Ziel dieser KI die Erzeugung von Text ist, wird es auch wichtig sein, diese Darstellung zu invertieren und daraus menschenlesbare Zeichenketten zu gewinnen. Hierfür können Sie `preprocessing.StringLookup(..., invert=True)` verwenden.  "]},{"cell_type":"markdown","metadata":{"id":"uenivzwqsDhp"},"source":["Hinweis: Verwenden Sie hier statt der Übergabe des mit `sorted(set(text))` erzeugten Originalvokabulars die Methode `get_vocabulary()` der Schicht `preprocessing.StringLookup`, damit die Padding- und `[UNK]`-Token auf die gleiche Weise gesetzt werden."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Wd2m3mqkDjRj","executionInfo":{"status":"ok","timestamp":1650699087654,"user_tz":-120,"elapsed":13,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n","    vocabulary=ids_from_chars.get_vocabulary(), invert=True)"]},{"cell_type":"markdown","metadata":{"id":"pqTDDxS-s-H8"},"source":["Diese Schicht gewinnt die Zeichen aus den Vektoren der IDs und gibt sie als `tf.RaggedTensor` von Zeichen zurück:"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1650699087654,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"c2GCh0ySD44s","outputId":"82852342-cf0a-41f3-b965-13f16919bc1a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"]},"metadata":{},"execution_count":12}],"source":["chars = chars_from_ids(ids)\n","chars"]},{"cell_type":"markdown","metadata":{"id":"-FeW5gqutT3o"},"source":["Sie können `tf.strings.reduce_join` verwenden, um die Zeichen wieder zu Strings zu verbinden. "]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":342,"status":"ok","timestamp":1650699087993,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"zxYI-PeltqKP","outputId":"bc41ebed-4c29-458f-96f3-0cf8b9c512e9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([b'abcdefg', b'xyz'], dtype=object)"]},"metadata":{},"execution_count":13}],"source":["tf.strings.reduce_join(chars, axis=-1).numpy()"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"w5apvBDn9Ind","executionInfo":{"status":"ok","timestamp":1650699087993,"user_tz":-120,"elapsed":3,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["def text_from_ids(ids):\n","  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"]},{"cell_type":"markdown","metadata":{"id":"bbmsf23Bymwe"},"source":["### The prediction task"]},{"cell_type":"markdown","metadata":{"id":"wssHQ1oGymwe"},"source":["Was ist bei einem Zeichen oder einer Zeichenfolge das wahrscheinlichste nächste Zeichen? Dies ist die Aufgabe, für die Sie das Modell trainieren. Die Eingabe für das Modell wird eine Sequenz von Zeichen sein, und du trainierst das Modell, um die Ausgabe - das nächste Zeichen - bei jedem Zeitschritt vorherzusagen.\n","\n","Da RNNs einen internen Zustand beibehalten, der von den zuvor gesehenen Elementen abhängt, ist die Frage: Was ist das nächste Zeichen, wenn alle bis zu diesem Zeitpunkt berechneten Zeichen vorliegen?\n"]},{"cell_type":"markdown","metadata":{"id":"hgsVvVxnymwf"},"source":["### Training Bespiele\n","\n","Als nächstes wird der Text in Beispielsequenzen aufgeteilt. Jede Eingabesequenz enthält `seq_length` Zeichen aus dem Text.\n","\n","Für jede Eingabesequenz enthalten die entsprechenden Ziele die gleiche Länge des Textes, nur um ein Zeichen nach rechts verschoben.\n","\n","Zerlegen Sie also den Text in Abschnitte von `seq_length+1`. Nehmen wir zum Beispiel an, `seq_length` ist 4 und unser Text ist \"Hallo\". Die Eingabesequenz wäre \"Hell\", und die Zielsequenz \"ello\".\n","\n","Verwenden Sie dazu zunächst die Funktion `tf.data.Dataset.from_tensor_slices`, um den Textvektor in einen Strom von Zeichenindizes zu konvertieren."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":424,"status":"ok","timestamp":1650699088414,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"UopbsKi88tm5","outputId":"b38a43fc-d0dc-4f14-9b2b-c34238eb675b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(560933,), dtype=int64, numpy=array([52, 68, 65, ..., 16,  2,  1])>"]},"metadata":{},"execution_count":15}],"source":["all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n","all_ids"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"qmxrYDCTy-eL","executionInfo":{"status":"ok","timestamp":1650699088415,"user_tz":-120,"elapsed":14,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1650699088415,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"cjH5v45-yqqH","outputId":"6ced5183-008a-4648-bf5d-11286305376e"},"outputs":[{"output_type":"stream","name":"stdout","text":["T\n","h\n","e\n"," \n","P\n","r\n","o\n","j\n","e\n","c\n"]}],"source":["for ids in ids_dataset.take(10):\n","    print(chars_from_ids(ids).numpy().decode('utf-8'))"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"C-G2oaTxy6km","executionInfo":{"status":"ok","timestamp":1650699088415,"user_tz":-120,"elapsed":8,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["seq_length = 100\n","examples_per_epoch = len(text)//(seq_length+1)"]},{"cell_type":"markdown","metadata":{"id":"-ZSYAcQV8OGP"},"source":["Mit der \"Batch\"-Methode können Sie diese einzelnen Zeichen leicht in Sequenzen der gewünschten Größe umwandeln."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1650699088416,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"BpdjRO2CzOfZ","outputId":"b96e01a2-0992-4be6-a854-e844870ddfc3"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[b'T' b'h' b'e' b' ' b'P' b'r' b'o' b'j' b'e' b'c' b't' b' ' b'G' b'u'\n"," b't' b'e' b'n' b'b' b'e' b'r' b'g' b' ' b'E' b'B' b'o' b'o' b'k' b' '\n"," b'o' b'f' b' ' b'F' b'a' b'u' b's' b't' b':' b' ' b'D' b'e' b'r' b' '\n"," b'T' b'r' b'a' b'g' b'\\xc3\\xb6' b'd' b'i' b'e' b' ' b'e' b'r' b's' b't'\n"," b'e' b'r' b' ' b'T' b'e' b'i' b'l' b',' b' ' b'b' b'y' b' ' b'\\r' b'\\n'\n"," b'J' b'o' b'h' b'a' b'n' b'n' b' ' b'W' b'o' b'l' b'f' b'g' b'a' b'n'\n"," b'g' b' ' b'v' b'o' b'n' b' ' b'G' b'o' b'e' b't' b'h' b'e' b'\\r' b'\\n'\n"," b'\\r' b'\\n' b'T' b'h'], shape=(101,), dtype=string)\n"]}],"source":["sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n","\n","for seq in sequences.take(1):\n","  print(chars_from_ids(seq))"]},{"cell_type":"markdown","metadata":{"id":"5PHW902-4oZt"},"source":["Es ist einfacher zu sehen, was dies bewirkt, wenn Sie die Token wieder zu Strings zusammenfügen:"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":436,"status":"ok","timestamp":1650699088849,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"QO32cMWu4a06","outputId":"83b42974-ade2-4a27-8c9a-2930d1928684"},"outputs":[{"output_type":"stream","name":"stdout","text":["b'The Project Gutenberg EBook of Faust: Der Trag\\xc3\\xb6die erster Teil, by \\r\\nJohann Wolfgang von Goethe\\r\\n\\r\\nTh'\n","b'is eBook is for the use of anyone anywhere at no cost and with\\r\\nalmost no restrictions whatsoever.  Y'\n","b'ou may copy it, give it away or\\r\\nre-use it under the terms of the Project Gutenberg License included\\r'\n","b'\\nwith this eBook or online at www.gutenberg.net\\r\\n\\r\\n\\r\\nTitle: Faust: Der Trag\\xc3\\xb6die erster Teil\\r\\n\\r\\nAuthor'\n","b': Johann Wolfgang von Goethe\\r\\n\\r\\nPosting Date: January 26, 2010 [EBook #2229]\\r\\nRelease Date: June 2000'\n"]}],"source":["for seq in sequences.take(5):\n","  print(text_from_ids(seq).numpy())"]},{"cell_type":"markdown","metadata":{"id":"UbLcIPBj_mWZ"},"source":["Fürs Training benötigst Du einen Datensatz mit `(Eingabe, Bezeichnung)`-Paaren. Wobei `Eingabe` und \n","Label\" Sequenzen sind. Bei jedem Zeitschritt ist die Eingabe das aktuelle Zeichen und das Label ist das nächste Zeichen. \n","\n","Hier ist eine Funktion, die eine Sequenz als Eingabe nimmt, sie dupliziert und verschiebt, um die Eingabe und das Label für jeden Zeitschritt auszurichten:"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"9NGu-FkO_kYU","executionInfo":{"status":"ok","timestamp":1650699088849,"user_tz":-120,"elapsed":22,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["def split_input_target(sequence):\n","    input_text = sequence[:-1]\n","    target_text = sequence[1:]\n","    return input_text, target_text"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1650699088849,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"WxbDTJTw5u_P","outputId":"2b0a1623-62e6-4e0a-f4db-becbac1febe5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n"," ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"]},"metadata":{},"execution_count":22}],"source":["split_input_target(list(\"Tensorflow\"))"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"B9iKPXkw5xwa","executionInfo":{"status":"ok","timestamp":1650699088850,"user_tz":-120,"elapsed":17,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["dataset = sequences.map(split_input_target)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1650699088850,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"GNbw-iR0ymwj","outputId":"9ef1606c-fe4b-4430-ddcd-405ca658c609"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input : b'The Project Gutenberg EBook of Faust: Der Trag\\xc3\\xb6die erster Teil, by \\r\\nJohann Wolfgang von Goethe\\r\\n\\r\\nT'\n","Target: b'he Project Gutenberg EBook of Faust: Der Trag\\xc3\\xb6die erster Teil, by \\r\\nJohann Wolfgang von Goethe\\r\\n\\r\\nTh'\n"]}],"source":["for input_example, target_example in dataset.take(1):\n","    print(\"Input :\", text_from_ids(input_example).numpy())\n","    print(\"Target:\", text_from_ids(target_example).numpy())"]},{"cell_type":"markdown","metadata":{"id":"MJdfPmdqzf-R"},"source":["### Create training batches\n","\n","Sie haben `tf.data` verwendet, um den Text in handhabbare Sequenzen aufzuteilen. Aber bevor Sie diese Daten in das Modell einspeisen, müssen Sie die Daten mischen und in Stapel packen."]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1650699088850,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"p2pGotuNzf-S","outputId":"e04e2001-8f4a-4c19-c17c-63eb14afc033"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PrefetchDataset element_spec=(TensorSpec(shape=(128, 100), dtype=tf.int64, name=None), TensorSpec(shape=(128, 100), dtype=tf.int64, name=None))>"]},"metadata":{},"execution_count":25}],"source":["# Batch size\n","BATCH_SIZE = 128\n","\n","# Buffer size to shuffle the dataset\n","# (TF data is designed to work with possibly infinite sequences,\n","# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n","# it maintains a buffer in which it shuffles elements).\n","BUFFER_SIZE = 20000\n","\n","dataset = (\n","    dataset\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE, drop_remainder=True)\n","    .prefetch(tf.data.experimental.AUTOTUNE))\n","\n","dataset"]},{"cell_type":"markdown","metadata":{"id":"r6oUuElIMgVx"},"source":["## Build The Model"]},{"cell_type":"markdown","metadata":{"id":"m8gPwEjRzf-Z"},"source":["In diesem Abschnitt wird das Modell als Subklasse `keras.Model` definiert (Details siehe [Erstellen neuer Schichten und Modelle über Subklassen] (https://www.tensorflow.org/guide/keras/custom_layers_and_models)). \n","\n","Dieses Modell hat drei Schichten:\n","\n","* `tf.keras.layers.Embedding`: Die Eingabeschicht. Eine trainierbare Nachschlagetabelle, die jede Zeichen-ID auf einen Vektor mit den Dimensionen `embedding_dim` abbildet;\n","* `tf.keras.layers.GRU`: Ein Typ von RNN mit der Größe `units=rnn_units` (Sie können hier auch eine LSTM-Schicht verwenden.)\n","* `tf.keras.layers.Dense`: Die Ausgabeschicht, mit Ausgaben der Größe `vocab_size`. Sie gibt für jedes Zeichen im Vokabular ein Logit aus. Dies sind die Log-Wahrscheinlichkeiten für jedes Zeichen gemäß dem Modell."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"zHT8cLh7EAsg","executionInfo":{"status":"ok","timestamp":1650699088850,"user_tz":-120,"elapsed":6,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["# Length of the vocabulary in chars\n","vocab_size = len(vocab)\n","\n","# The embedding dimension\n","embedding_dim = 512\n","\n","# Number of RNN units\n","rnn_units = 1024 #2048"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"wj8HQ2w8z4iO","executionInfo":{"status":"ok","timestamp":1650699088851,"user_tz":-120,"elapsed":7,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["class MyModel(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, rnn_units):\n","    super().__init__(self)\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(rnn_units,\n","                                   return_sequences=True,\n","                                   return_state=True)\n","    self.dense = tf.keras.layers.Dense(vocab_size)\n","\n","  def call(self, inputs, states=None, return_state=False, training=False):\n","    x = inputs\n","    x = self.embedding(x, training=training)\n","    if states is None:\n","      states = self.gru.get_initial_state(x)\n","    x, states = self.gru(x, initial_state=states, training=training)\n","    x = self.dense(x, training=training)\n","\n","    if return_state:\n","      return x, states\n","    else:\n","      return x"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"IX58Xj9z47Aw","executionInfo":{"status":"ok","timestamp":1650699088851,"user_tz":-120,"elapsed":7,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["model = MyModel(\n","    # Be sure the vocabulary size matches the `StringLookup` layers.\n","    vocab_size=len(ids_from_chars.get_vocabulary()),\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units)"]},{"cell_type":"markdown","metadata":{"id":"RkA5upJIJ7W7"},"source":["Für jedes Zeichen sucht das Modell die Einbettung, führt die GRU einen Zeitschritt mit der Einbettung als Eingabe aus und wendet die dichte Schicht an, um Logits zu erzeugen, die die Log-Wahrscheinlichkeit des nächsten Zeichens vorhersagen:\n","\n","![A drawing of the data passing through the model](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/images/text_generation_training.png?raw=1)"]},{"cell_type":"markdown","metadata":{"id":"gKbfm04amhXk"},"source":["Hinweis: Zum Training könnten Sie hier ein `keras.Sequential`-Modell verwenden. Um später Text zu generieren, müssen Sie den internen Zustand des RNNs verwalten. Es ist einfacher, die Eingabe- und Ausgabeoptionen für den Zustand im Voraus einzubinden, als die Modellarchitektur später umzustellen. Weitere Details finden Sie in der [Keras RNN-Anleitung](https://www.tensorflow.org/guide/keras/rnn#rnn_state_reuse)."]},{"cell_type":"markdown","metadata":{"id":"-ubPo0_9Prjb"},"source":["## Try the model\n","Führe nun das Modell aus, um zu sehen, ob es sich wie erwartet verhält.\n","\n","Prüfen Sie zunächst die Form der Ausgabe:"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4616,"status":"ok","timestamp":1650699093461,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"C-_70kKAPrPU","outputId":"14901ee9-0359-4bf7-df36-4c67c4b7378d"},"outputs":[{"output_type":"stream","name":"stdout","text":["(128, 100, 95) # (batch_size, sequence_length, vocab_size)\n"]}],"source":["for input_example_batch, target_example_batch in dataset.take(1):\n","    example_batch_predictions = model(input_example_batch)\n","    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"]},{"cell_type":"markdown","metadata":{"id":"Q6NzLBi4VM4o"},"source":["Im obigen Beispiel ist die Sequenzlänge der Eingabe \"100\", aber das Modell kann auf Eingaben beliebiger Länge ausgeführt werden:"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1650699093461,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"vPGmAAXmVLGC","outputId":"734774d0-a07c-4da9-ed66-949e27bc60b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"my_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       multiple                  48640     \n","                                                                 \n"," gru (GRU)                   multiple                  4724736   \n","                                                                 \n"," dense (Dense)               multiple                  97375     \n","                                                                 \n","=================================================================\n","Total params: 4,870,751\n","Trainable params: 4,870,751\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"uwv0gEkURfx1"},"source":["Um tatsächliche Vorhersagen aus dem Modell zu erhalten, müssen Sie eine Stichprobe aus der Ausgabeverteilung ziehen, um tatsächliche Zeichenindizes zu erhalten. Diese Verteilung ist durch die Logits über das Zeichenvokabular definiert.\n","\n","Hinweis: Es ist wichtig, aus dieser Verteilung eine _Stichprobe_ zu nehmen, da das Modell durch die Verwendung des _argmax_ der Verteilung leicht in einer Schleife stecken bleiben kann.\n","\n","Probieren Sie es für das erste Beispiel im Stapel aus:"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"4V4MfFg0RQJg","executionInfo":{"status":"ok","timestamp":1650699093461,"user_tz":-120,"elapsed":13,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n","sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"]},{"cell_type":"markdown","metadata":{"id":"QM1Vbxs_URw5"},"source":["Dadurch erhalten wir in jedem Zeitschritt eine Vorhersage des nächsten Zeichenindexes:"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1650699093461,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"YqFMUQc_UFgM","outputId":"82dd8f02-2fb0-4009-e9f3-d1f8c2d9f595"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([31,  4, 34, 54, 40,  2, 58, 82, 29,  3, 54, 51, 40, 84,  8, 54, 55,\n","       50, 72, 39, 73, 37, 79, 60, 50, 56, 67, 91, 78, 14, 68, 68, 19, 40,\n","        5, 83, 13, 57,  7, 18, 35, 20, 55, 70, 60, 55,  1, 27, 20, 53, 51,\n","       21, 70, 48, 26, 63,  1, 65, 26, 32, 54, 89, 27, 37, 77, 73, 43, 65,\n","       85, 23, 23, 71, 17, 92, 78, 83, 42, 29, 51, 56, 20, 53, 91, 11,  4,\n","       91, 45,  1,  7,  9, 34, 46,  7, 87,  0, 77, 78, 82, 27, 47])"]},"metadata":{},"execution_count":32}],"source":["sampled_indices"]},{"cell_type":"markdown","metadata":{"id":"LfLtsP3mUhCG"},"source":["Dekodieren Sie diese, um den von diesem untrainierten Modell vorhergesagten Text zu sehen:"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1650699093462,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"xWcFwPwLSo05","outputId":"913a60e7-9b41-4b46-8425-36514dddce86"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input:\n"," b'et,\\r\\n  \\xc3\\xbcberfl\\xc3\\xbcssig, ewig helle\\r\\n  Rings durch alle Welten flie\\xc3\\x9fet--\\r\\n\\r\\n  MARIA AEGYPTIACA:\\r\\n  Bei de'\n","\n","Next Char Predictions:\n"," b'?!BVH\\rZv; VSHx%VWRlGmEs]RXg\\xc3\\xa4r,hh1H\"w+Y$0C2Wj]W\\n92US3jP8c\\ne8@V\\xc3\\x9c9EqmKey55k/\\xc3\\xb6rwJ;SX2U\\xc3\\xa4)!\\xc3\\xa4M\\n$\\'BN$\\xc3\\x84[UNK]qrv9O'\n"]}],"source":["print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n","print()\n","print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"]},{"cell_type":"markdown","metadata":{"id":"LJL0Q0YPY6Ee"},"source":["## Train the model"]},{"cell_type":"markdown","metadata":{"id":"YCbHQHiaa4Ic"},"source":["An diesem Punkt kann das Problem als Standard-Klassifikationsproblem behandelt werden. In Anbetracht des vorherigen RNN-Zustands und der Eingabe in diesem Zeitschritt, sagen Sie die Klasse des nächsten Zeichens voraus."]},{"cell_type":"markdown","metadata":{"id":"trpqTWyvk0nr"},"source":["### Attach an optimizer, and a loss function"]},{"cell_type":"markdown","metadata":{"id":"UAjbjY03eiQ4"},"source":["Die Standardverlustfunktion `tf.keras.losses.sparse_categorical_crossentropy` funktioniert in diesem Fall, weil sie auf die letzte Dimension der Vorhersagen angewendet wird.\n","\n","Da dein Modell Logits zurückgibt, müssen Sie das Flag `from_logits` setzen.\n"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"ZOeWdgxNFDXq","executionInfo":{"status":"ok","timestamp":1650699093462,"user_tz":-120,"elapsed":5,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":319,"status":"ok","timestamp":1650699093777,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"4HrXTACTdzY-","outputId":"2c094f54-a892-425a-a6bd-0ad900d8a4de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction shape:  (128, 100, 95)  # (batch_size, sequence_length, vocab_size)\n","Mean loss:         4.5542107\n"]}],"source":["example_batch_loss = loss(target_example_batch, example_batch_predictions)\n","mean_loss = example_batch_loss.numpy().mean()\n","print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n","print(\"Mean loss:        \", mean_loss)"]},{"cell_type":"markdown","metadata":{"id":"vkvUIneTFiow"},"source":["Ein neu initialisiertes Modell sollte sich seiner Sache nicht zu sicher sein, die ausgegebenen Logits sollten alle ähnliche Größenordnungen haben. Um dies zu bestätigen, können Sie prüfen, ob der Exponentialwert des mittleren Verlusts ungefähr gleich der Vokabulargröße ist. Ein viel höherer Verlust bedeutet, dass das Modell sich seiner falschen Antworten sicher ist und schlecht initialisiert wurde:"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1650699093777,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"MAJfS5YoFiHf","outputId":"76be3cc9-d029-42cd-873b-bc7cbd749767"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["95.03171"]},"metadata":{},"execution_count":36}],"source":["tf.exp(mean_loss).numpy()"]},{"cell_type":"markdown","metadata":{"id":"jeOXriLcymww"},"source":["Konfigurieren Sie das Trainingsverfahren mit der Methode `tf.keras.Model.compile`. Verwenden Sie `tf.keras.optimizers.Adam` mit Standardargumenten und der Verlustfunktion."]},{"cell_type":"code","execution_count":37,"metadata":{"id":"DDl1_Een6rL0","executionInfo":{"status":"ok","timestamp":1650699093777,"user_tz":-120,"elapsed":7,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["model.compile(optimizer='adam', loss=loss)"]},{"cell_type":"markdown","metadata":{"id":"ieSJdchZggUj"},"source":["### Configure checkpoints"]},{"cell_type":"markdown","metadata":{"id":"C6XBUUavgF56"},"source":["Verwenden Sie ein `tf.keras.callbacks.ModelCheckpoint`, um sicherzustellen, dass Checkpoints während des Trainings gespeichert werden:"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"W6fWTriUZP-n","executionInfo":{"status":"ok","timestamp":1650699093778,"user_tz":-120,"elapsed":8,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["# Directory where the checkpoints will be saved\n","checkpoint_dir = './training_checkpoints'\n","# Name of the checkpoint files\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)"]},{"cell_type":"markdown","metadata":{"id":"3Ky3F_BhgkTW"},"source":["### Execute the training"]},{"cell_type":"markdown","metadata":{"id":"IxdOA-rgyGvs"},"source":["\n","\n","Um die Trainingszeit angemessen zu halten, verwenden Sie 10 Epochen zum Trainieren des Modells. Stellen Sie in Colab die Laufzeit auf GPU für schnelleres Training ein."]},{"cell_type":"code","execution_count":39,"metadata":{"id":"7yGBE2zxMMHs","executionInfo":{"status":"ok","timestamp":1650699093778,"user_tz":-120,"elapsed":8,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["EPOCHS = 5"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":74726,"status":"ok","timestamp":1650699168496,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"UK-hmKjYVoll","outputId":"859f801b-d86a-445f-dab8-f3a601537ae1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","43/43 [==============================] - 13s 225ms/step - loss: 3.4303\n","Epoch 2/5\n","43/43 [==============================] - 11s 226ms/step - loss: 2.3361\n","Epoch 3/5\n","43/43 [==============================] - 11s 225ms/step - loss: 2.1125\n","Epoch 4/5\n","43/43 [==============================] - 11s 226ms/step - loss: 1.9936\n","Epoch 5/5\n","43/43 [==============================] - 11s 229ms/step - loss: 1.8983\n"]}],"source":["history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"]},{"cell_type":"markdown","metadata":{"id":"kKkD5M6eoSiN"},"source":["## Generate text"]},{"cell_type":"markdown","metadata":{"id":"oIdQ8c8NvMzV"},"source":["Der einfachste Weg, mit diesem Modell Text zu erzeugen, ist, es in einer Schleife laufen zu lassen und den internen Zustand des Modells während der Ausführung zu verfolgen.\n","\n","![Um Text zu generieren, wird die Ausgabe des Modells an die Eingabe zurückgegeben](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/images/text_generation_sampling.png?raw=1)\n","\n","Jedes Mal, wenn Sie das Modell aufrufen, übergibst du etwas Text und einen internen Zustand. Das Modell gibt eine Vorhersage für das nächste Zeichen und seinen neuen Zustand zurück. Übergibst du die Vorhersage und den Zustand zurück, um die Texterzeugung fortzusetzen."]},{"cell_type":"markdown","metadata":{"id":"DjGz1tDkzf-u"},"source":["Im Folgenden wird eine einstufige Vorhersage getroffen:"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"iSBU1tHmlUSs","executionInfo":{"status":"ok","timestamp":1650699168497,"user_tz":-120,"elapsed":11,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["class OneStep(tf.keras.Model):\n","  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n","    super().__init__()\n","    self.temperature = temperature\n","    self.model = model\n","    self.chars_from_ids = chars_from_ids\n","    self.ids_from_chars = ids_from_chars\n","\n","    # Create a mask to prevent \"[UNK]\" from being generated.\n","    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n","    sparse_mask = tf.SparseTensor(\n","        # Put a -inf at each bad index.\n","        values=[-float('inf')]*len(skip_ids),\n","        indices=skip_ids,\n","        # Match the shape to the vocabulary\n","        dense_shape=[len(ids_from_chars.get_vocabulary())])\n","    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n","\n","  @tf.function\n","  def generate_one_step(self, inputs, states=None):\n","    # Convert strings to token IDs.\n","    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n","    input_ids = self.ids_from_chars(input_chars).to_tensor()\n","\n","    # Run the model.\n","    # predicted_logits.shape is [batch, char, next_char_logits]\n","    predicted_logits, states = self.model(inputs=input_ids, states=states,\n","                                          return_state=True)\n","    # Only use the last prediction.\n","    predicted_logits = predicted_logits[:, -1, :]\n","    predicted_logits = predicted_logits/self.temperature\n","    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n","    predicted_logits = predicted_logits + self.prediction_mask\n","\n","    # Sample the output logits to generate token IDs.\n","    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n","    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n","\n","    # Convert from token ids to characters\n","    predicted_chars = self.chars_from_ids(predicted_ids)\n","\n","    # Return the characters and model state.\n","    return predicted_chars, states"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"fqMOuDutnOxK","executionInfo":{"status":"ok","timestamp":1650699168497,"user_tz":-120,"elapsed":10,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["one_step_model = OneStep(model, chars_from_ids, ids_from_chars, 0.7)"]},{"cell_type":"markdown","metadata":{"id":"p9yDoa0G3IgQ"},"source":["Lass es in einer Schleife laufen, um einen Text zu erzeugen. Wenn du dir den generierten Text aniehst, wirst du sehen, dass das Modell weiß, wann es groß schreibt, Absätze bildet und ein zu deinem Text ähnliches Schreibvokabular imitiert. Mit der geringen Anzahl von Trainingsepochen hat es noch nicht gelernt, zusammenhängende Sätze zu bilden.\n","\n","ROMEO: ist hier das startwort, natürlich kann hier was anderes gewählt werden."]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8793,"status":"ok","timestamp":1650699177581,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"ST7PSyk9t1mT","outputId":"85d3c84c-21f9-4d93-dde6-67a3dfe5f08d"},"outputs":[{"output_type":"stream","name":"stdout","text":["ROMEO:\r\n","  Dan welng und Werwiten Gebeut und dust die Sang ein Gegegänztest.\r\n","\r\n","  FAUST:\r\n","  Ich lar im grettem Sthin aus und sich aus einn ander mich,\r\n","  So schören Hast du soglich einen Wehich graufein Gestioben,\r\n","  Wied und hie wieder sind und ihre anzu zu verlicht,\r\n","  Die Leist zu schort in an die Sand den Harden, chennemt, de nocht,\r\n","  Min nicht der fürnen witheibe geuschen wir sie sich und sohleinglich ster und Ratze der Sculeben geist inn sie sind Hert der Gestens andund dem Speine.\r\n","\r\n","  FAUST:\r\n","  Hern gehnigest zu immer dochen, ist Ehn ihr dehn floct,\r\n","  Dein Feraff vor sin wirlichten weinen, Lacht lieht gereinel\r\n","  Doch warm seinen hände gaunen so ich sehnen, Hert nicht!\r\n","  Ich fürm und es geinde Herrs es aulemer, der Gesten Proje tert.\r\n","\r\n","  FAUST:\r\n","  Den rich, auf in gewause, sich sin mich er der Gelle\r\n","  Won dee mom deh nicht gange schonten,\r\n","  Die Wand mer weingand, wein die Auch Zumer vort vonichen werben steten sein.\r\n","  Wie yin ein jeden sich Fraust.\r\n","  Was immer erthe min zu ind der Unde klichtt.\r\n","\r\n","  MEPHISTOPHELES:\r\n","  Wen wir im mirht die Mängeren Kritze singen.\r\n","  Die Schmeine trong zu des Geister Schwehn,\r\n","  Wan sch nicht zu und be beinen Hon;\r\n","  Int dich dir inner Sind deisen ingestem Jugend zuen,\r\n","  Amschings er berein mies wir heinet auf ihr zu deinen Guten star bebehn.\r\n","\r\n","  (FAUST:\r\n","  Ein Miersen hrigen, der Glaschen Sterten Fäusen wind der Gebenderg.\r\n","\r\n","  MAPHISTOPHELES:\r\n","  Dur fauf ihr ihr dacht stellem Stalben Lut.\r\n","\r\n","  FAUS:\r\n","  Dan bist der Tant under wird sie wertand, sie ich alturren loch;\r\n","  Me nich sie ein sie Meis ein Herter einen\r\n","  Alle schwie kerlügen,\r\n","  Den schluckt min Kaure Herd maß dem Nacht vor demprützen Hary in dart dir meinen Seinet zu versagren?\r\n","  Ich nwier wir einer Mitzer Bleuft,  is die Zurke merige auker warz  ich hier and hafen, schwang auf lachte sich spein underter sich wir ernen frie Meine\r\n","  Schwinge fühle Wan die Muter,\r\n","  Das wielen wahle, wir gestennaumen Schaure schlückgenn\r\n","  Und Stieft mich nich klau imm Stausen,  \n","\n","________________________________________________________________________________\n","\n","Run time: 8.645501136779785\n"]}],"source":["start = time.time()\n","states = None\n","next_char = tf.constant(['ROMEO:']) # DAS IST DAS STARTWORT\n","result = [next_char]\n","\n","for n in range(2000):\n","  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n","print('\\nRun time:', end - start)"]},{"cell_type":"markdown","metadata":{"id":"AM2Uma_-yVIq"},"source":["Das Einfachste, was Du tun kannst, um die Ergebnisse zu verbessern, ist, es länger zu trainieren (versuchen Sie `EPOCHS = 30`).\n","\n","Du kannst auch mit einer anderen Startzeichenfolge experimentieren, eine weitere RNN-Schicht hinzufügen, um die Genauigkeit des Modells zu verbessern, oder den Temeperaturparameter anpassen, um mehr oder weniger zufällige Vorhersagen zu erzeugen."]},{"cell_type":"markdown","metadata":{"id":"_OfbI4aULmuj"},"source":["Wenn Sie möchten, dass das Modell Text *schneller* erzeugt, ist es am einfachsten, die Texterzeugung zu stapeln. Im folgenden Beispiel generiert das Modell 5 Ausgaben in etwa der gleichen Zeit, die es für die obige Generierung von 1 Ausgabe benötigte. "]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3626,"status":"ok","timestamp":1650699181204,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"},"user_tz":-120},"id":"ZkLu7Y8UCMT7","outputId":"54f05c28-a1f2-45ab-91f6-edabe2d69acc"},"outputs":[{"output_type":"stream","name":"stdout","text":["ROMEO:\r\n","  Ender Mandich er auf der Schunnen, das Mengertu des Leicht, zurvollst von, woll man sich an dun auf er elten, die Geschenn;\r\n","  Due mand in die Under iptend har,\r\n","  Das werreit sich mer Gokeit der Projech Gewürkt,\r\n","  Sol' ich mir decht, nuch une Schäuten Gleich beriggender.\r\n","\r\n","  MARGACBER:\r\n","  Die sin der Hein die Sterkt endert nicht, im Lunder sie richt vor int grüffen nan die Herder.\r\n","  Me!  Dert sein Euch und Gat dan ein, ein Sich noche nicht;\r\n","  Ihr der Kand sir zurennon der Bleiben lichen,\r\n","  Dar seinen sich gester prau der Festenze Schinen siete wott doch fand ander Wielem Lirden;\r\n","  Ferm dor woret in ich ein do nuhnen mindes chehnen,\r\n","  De PHojen, wir ich zunen, Schinken!\r\n","  Hars nicht ich nicht du schwar del Werest, das Rocht.\r\n","  Har sich mein Seiden, forsten seid einen;\r\n","  Ich bein ein Getommen, micht er simmen Wom!\r\n","  Dan eine Gläckte wie son die Meich ing an sor und vorendert nich am auch num das in warks an der Sich das, eis wirmeinigter,\r\n","  Ich allen Sterft und rieben Bl \n","\n","________________________________________________________________________________\n","\n","Run time: 3.851836681365967\n"]}],"source":["start = time.time()\n","states = None\n","next_char = tf.constant(['ROMEO:'])\n","result = [next_char]\n","\n","for n in range(1000):\n","  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n","print('\\nRun time:', end - start)"]},{"cell_type":"markdown","metadata":{"id":"UlUQzwu6EXam"},"source":["## Exportieren Sie den Generator\n","\n","Dieses Einzelschrittmodell kann leicht [gespeichert und wiederhergestellt] werden (https://www.tensorflow.org/guide/saved_model), so dass Sie es überall verwenden können, wo ein `tf.saved_model` akzeptiert wird."]},{"cell_type":"code","execution_count":45,"metadata":{"id":"3Grk32H_CzsC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650699188854,"user_tz":-120,"elapsed":7661,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}},"outputId":"c73600fa-df7c-448a-ad5f-832d89df8563"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f541e9250d0>, because it is not built.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: one_step/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: one_step/assets\n"]}],"source":["tf.saved_model.save(one_step_model, 'one_step')\n","one_step_reloaded = tf.saved_model.load('one_step')"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"_Z9bb_wX6Uuu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650699189682,"user_tz":-120,"elapsed":829,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}},"outputId":"53b05a1d-05a5-403d-b69d-72ce8ccb3a37"},"outputs":[{"output_type":"stream","name":"stdout","text":["ROMEO:\r\n","  Wenwist tur trou sein in Glakt' wister affeine!\r\n","  Die Heies derer werder Zway dem Heiler Stie Z\n"]}],"source":["states = None\n","next_char = tf.constant(['ROMEO:'])\n","result = [next_char]\n","\n","for n in range(100):\n","  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"]},{"cell_type":"markdown","metadata":{"id":"Y4QwTjAM6A2O"},"source":["## Fortgeschrittene: Angepasstes Training\n","\n","Das obige Trainingsverfahren ist einfach, gibt Ihnen aber nicht viel Kontrolle.\n","Es verwendet Teacher-Forcing, das verhindert, dass schlechte Vorhersagen an das Modell zurückgegeben werden, so dass das Modell nie lernt, sich von Fehlern zu erholen.\n","\n","Nachdem Sie nun gesehen haben, wie das Modell manuell ausgeführt wird, werden Sie als nächstes die Trainingsschleife implementieren. Damit haben Sie einen Ansatzpunkt, wenn Sie z. B. _Lehrplan-Lernen_ implementieren möchten, um die Ausgabe des Modells im offenen Regelkreis zu stabilisieren.\n","\n","Der wichtigste Teil einer benutzerdefinierten Trainingsschleife ist die Funktion \"train step\".\n","\n","Verwenden Sie `tf.GradientTape`, um die Gradienten zu verfolgen. Sie können mehr über diesen Ansatz erfahren, indem Sie die [eager execution guide](https://www.tensorflow.org/guide/eager) lesen.\n","\n","Die grundlegende Vorgehensweise ist:\n","\n","1. Führen Sie das Modell aus und berechnen Sie den Verlust unter einem `tf.GradientTape`.\n","2. Berechnen Sie die Aktualisierungen und wenden Sie sie mithilfe des Optimierers auf das Modell an."]},{"cell_type":"code","execution_count":47,"metadata":{"id":"x0pZ101hjwW0","executionInfo":{"status":"ok","timestamp":1650699189682,"user_tz":-120,"elapsed":3,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["class CustomTraining(MyModel):\n","  @tf.function\n","  def train_step(self, inputs):\n","      inputs, labels = inputs\n","      with tf.GradientTape() as tape:\n","          predictions = self(inputs, training=True)\n","          loss = self.loss(labels, predictions)\n","      grads = tape.gradient(loss, model.trainable_variables)\n","      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","      return {'loss': loss}"]},{"cell_type":"markdown","metadata":{"id":"4Oc-eJALcK8B"},"source":["Die obige Implementierung der Methode `train_step` folgt den [Keras' `train_step`-Konventionen] (https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit). Dies ist optional, aber es erlaubt Ihnen, das Verhalten des Train-Schrittes zu ändern und trotzdem die Methoden `Model.compile` und `Model.fit` von Keras zu verwenden."]},{"cell_type":"code","execution_count":48,"metadata":{"id":"XKyWiZ_Lj7w5","executionInfo":{"status":"ok","timestamp":1650699189683,"user_tz":-120,"elapsed":3,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["model = CustomTraining(\n","    vocab_size=len(ids_from_chars.get_vocabulary()),\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units)"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"U817KUm7knlm","executionInfo":{"status":"ok","timestamp":1650699189683,"user_tz":-120,"elapsed":3,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}}},"outputs":[],"source":["model.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"o694aoBPnEi9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650699202648,"user_tz":-120,"elapsed":12967,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}},"outputId":"b9c3c958-a9b2-44a8-de4a-bc606e9fa1d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["43/43 [==============================] - 13s 225ms/step - loss: 3.3959\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f541e593150>"]},"metadata":{},"execution_count":50}],"source":["model.fit(dataset, epochs=1)"]},{"cell_type":"markdown","metadata":{"id":"W8nAtKHVoInR"},"source":["Oder wenn Sie mehr Kontrolle benötigen, können Sie Ihre eigene, komplett benutzerdefinierte Trainingsschleife schreiben:"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"d4tSNwymzf-q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650699308008,"user_tz":-120,"elapsed":105368,"user":{"displayName":"Philipp Kalytta","userId":"00402386790378594808"}},"outputId":"035f6de8-91c1-49a3-a61c-789f5f04e974"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Batch 0 Loss 2.5567\n","\n","Epoch 1 Loss: 2.3271\n","Time taken for 1 epoch 11.22 sec\n","________________________________________________________________________________\n","Epoch 2 Batch 0 Loss 2.2147\n","\n","Epoch 2 Loss: 2.1021\n","Time taken for 1 epoch 10.40 sec\n","________________________________________________________________________________\n","Epoch 3 Batch 0 Loss 2.0228\n","\n","Epoch 3 Loss: 1.9842\n","Time taken for 1 epoch 10.37 sec\n","________________________________________________________________________________\n","Epoch 4 Batch 0 Loss 1.9219\n","\n","Epoch 4 Loss: 1.8868\n","Time taken for 1 epoch 10.38 sec\n","________________________________________________________________________________\n","Epoch 5 Batch 0 Loss 1.8702\n","\n","Epoch 5 Loss: 1.7999\n","Time taken for 1 epoch 10.57 sec\n","________________________________________________________________________________\n","Epoch 6 Batch 0 Loss 1.7252\n","\n","Epoch 6 Loss: 1.7183\n","Time taken for 1 epoch 10.39 sec\n","________________________________________________________________________________\n","Epoch 7 Batch 0 Loss 1.6762\n","\n","Epoch 7 Loss: 1.6431\n","Time taken for 1 epoch 10.39 sec\n","________________________________________________________________________________\n","Epoch 8 Batch 0 Loss 1.6329\n","\n","Epoch 8 Loss: 1.5753\n","Time taken for 1 epoch 10.45 sec\n","________________________________________________________________________________\n","Epoch 9 Batch 0 Loss 1.5028\n","\n","Epoch 9 Loss: 1.5124\n","Time taken for 1 epoch 10.43 sec\n","________________________________________________________________________________\n","Epoch 10 Batch 0 Loss 1.4711\n","\n","Epoch 10 Loss: 1.4575\n","Time taken for 1 epoch 10.52 sec\n","________________________________________________________________________________\n"]}],"source":["EPOCHS = 10\n","\n","mean = tf.metrics.Mean()\n","\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","\n","    mean.reset_states()\n","    for (batch_n, (inp, target)) in enumerate(dataset):\n","        logs = model.train_step([inp, target])\n","        mean.update_state(logs['loss'])\n","\n","        if batch_n % 50 == 0:\n","            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n","            print(template)\n","\n","    # saving (checkpoint) the model every 5 epochs\n","    if (epoch + 1) % 5 == 0:\n","        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n","\n","    print()\n","    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n","    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n","    print(\"_\"*80)\n","\n","model.save_weights(checkpoint_prefix.format(epoch=epoch))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"LNU-03-TEXT","provenance":[{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/text_generation.ipynb","timestamp":1617182072077}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}